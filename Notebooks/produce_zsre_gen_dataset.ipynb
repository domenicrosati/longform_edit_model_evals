{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "DATASET_PATH = '../data/zsre/zsre_mend_eval.json'\n",
    "with open(DATASET_PATH, 'r') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ent_id2label ={}\n",
    "with open('../data/ent_id2label.json', 'r') as f:\n",
    "    ent_id2label = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwikidata.entity import WikidataItem, WikidataProperty\n",
    "import qwikidata.linked_data_interface as ldi\n",
    "import functools\n",
    "import traceback\n",
    "import time\n",
    "import requests\n",
    "\n",
    "\n",
    "WIKIDATA_SPARQL_URL = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "def return_sparql_query_results(\n",
    "    query_string: str, wikidata_sparql_url: str = WIKIDATA_SPARQL_URL\n",
    ") -> dict:\n",
    "    \"\"\"Send a SPARQL query and return the JSON formatted result.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query_string: str\n",
    "      SPARQL query string\n",
    "    wikidata_sparql_url: str, optional\n",
    "      wikidata SPARQL endpoint to use\n",
    "    \"\"\"\n",
    "    resp = requests.get(\n",
    "        wikidata_sparql_url, params={\"query\": query_string, \"format\": \"json\"}\n",
    "    )\n",
    "    # check for rate limit exceeded\n",
    "    if resp.status_code == 429:\n",
    "        while resp.status_code == 429:\n",
    "            time.sleep(0.5)\n",
    "            resp = requests.get(\n",
    "                wikidata_sparql_url, params={\"query\": query_string, \"format\": \"json\"}\n",
    "            )\n",
    "\n",
    "    return resp.json()\n",
    "\n",
    "\n",
    "LABEL_TO_QID = \"\"\"\n",
    "PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "SELECT DISTINCT ?item\n",
    "WHERE {{\n",
    "\n",
    "  # make input string into a language-tagged string\n",
    "  BIND( STRLANG(\"{}\", \"en\") AS ?label ) .\n",
    "\n",
    "  # search all items that have this languaged-tagged string as label\n",
    "  ?item rdfs:label ?label .\n",
    "\n",
    "  # extract the last path segment of the URI\n",
    "  BIND(STRAFTER(STR(?item), STR(wd:)) AS ?qid) .\n",
    "  # get count of propertes as heuristic for popularity\n",
    "    ?item ?p ?statement .\n",
    "}} order by desc(?p) limit 1\n",
    "\"\"\"\n",
    "\n",
    "ALL_ENTITIES_THAT_HAVE_THIS_AS_AN_OBJECT_TO_ANY_PROPERTY = \"\"\"\n",
    "SELECT DISTINCT ?item\n",
    "WHERE {{\n",
    "  ?item ?p wd:{0} .\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "ALL_ENTITIES_THAT_HAVE_THIS_AS_AN_OBJECT_TO_ANY_PROPERTY_AND_THIS_HAS = \"\"\"\n",
    "SELECT DISTINCT ?item\n",
    "WHERE {{\n",
    "  ?item ?p wd:{0} .\n",
    "  wd:{1} ?p2 ?item. # change to ?p for mutual property\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "ALL_ENTITIES_THAT_HAVE_THIS_AS_AN_OBJECT_TO_ANY_PROPERTY_AND_PRE_EDIT = \"\"\"\n",
    "SELECT DISTINCT ?item\n",
    "WHERE {{\n",
    "  ?item ?p wd:{0} .\n",
    "  ?item ?p2 wd:{1} .\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "COUPLED_ENTITIES_QUERY = \"\"\"\n",
    "SELECT ?item\n",
    "WHERE {{\n",
    "  {{ ?item ?p wd:{0} . }}\n",
    "  UNION\n",
    "  {{ wd:{0} ?p ?item . }}\n",
    "  {{ ?item ?p2 wd:{1} . }}\n",
    "  UNION\n",
    "  {{ wd:{1} ?p2 ?item . }}\n",
    "}} GROUP BY ?item ORDER BY DESC(COUNT(?item)) LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_wikidata_item_from_label(label):\n",
    "    try:\n",
    "      results = return_sparql_query_results(LABEL_TO_QID.format(label))['results']\n",
    "      if not results['bindings']:\n",
    "        return None\n",
    "      qid = results['bindings'][0]['item']['value']\n",
    "    except Exception as e:\n",
    "      traceback.print_exc()\n",
    "      print(e)\n",
    "      return None\n",
    "    entity_dict = ldi.get_entity_dict_from_api(qid.strip('http://www.wikidata.org/entity/'))\n",
    "    return WikidataItem(entity_dict)\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_wikidata_item_from_id(qid):\n",
    "    try:\n",
    "       entity_dict = ldi.get_entity_dict_from_api(qid)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(e)\n",
    "\n",
    "        return None\n",
    "    return WikidataItem(entity_dict)\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_wikidata_label_from_id(qid):\n",
    "    try:\n",
    "      entity_label = ent_id2label[qid]\n",
    "      return entity_label\n",
    "    except Exception as e:\n",
    "      entity = get_wikidata_item_from_id(qid)\n",
    "      if entity:\n",
    "        return entity.get_label()\n",
    "      else:\n",
    "        return ''\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_wikidata_property_from_id(pid):\n",
    "    try:\n",
    "      entity_dict = ldi.get_entity_dict_from_api(pid)\n",
    "    except Exception as e:\n",
    "      traceback.print_exc()\n",
    "      print(e)\n",
    "      return None\n",
    "    return WikidataProperty(entity_dict)\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_all_entities_that_have_this_as_an_object_to_any_property(qid):\n",
    "    try:\n",
    "      items = return_sparql_query_results(ALL_ENTITIES_THAT_HAVE_THIS_AS_AN_OBJECT_TO_ANY_PROPERTY.format(qid, qid))['results']['bindings']\n",
    "    except Exception as e:\n",
    "      traceback.print_exc()\n",
    "      print(e)\n",
    "      return []\n",
    "    entities = []\n",
    " \n",
    "    for item in items:\n",
    "      if 'http://www.wikidata.org/entity/Q' in item['item']['value']:\n",
    "        entities.append(get_wikidata_item_from_id(item['item']['value'].strip('http://www.wikidata.org/entity/')))\n",
    "    return entities\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_coupled_entities(qid_entity, qid_change):\n",
    "    try:\n",
    "      items = return_sparql_query_results(COUPLED_ENTITIES_QUERY.format(qid_entity, qid_change))['results']['bindings']\n",
    "    except Exception as e:\n",
    "      traceback.print_exc()\n",
    "      print(e)\n",
    "      return []\n",
    "\n",
    "    entities = []\n",
    "    for item in items:\n",
    "      if 'http://www.wikidata.org/entity/Q' in item['item']['value']:\n",
    "        entities.append(get_wikidata_item_from_id(item['item']['value'].strip('http://www.wikidata.org/entity/')))\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: getting the property label is slow\n",
    "# getting the ID is preferrable\n",
    "property_exclude_list = [\n",
    "    'instance of',\n",
    "    'copyright status',\n",
    "    'described by source',\n",
    "    'documentation files at',\n",
    "    'category',\n",
    "    'copyright representative',\n",
    "    'modified version of',\n",
    "    'topic',\n",
    "    'main regulatory text',\n",
    "    'open data portal',\n",
    "    'rating',\n",
    "    'follow',\n",
    "    'said to be the same as',\n",
    "    'twinned',\n",
    "    'copyright license',\n",
    "    'list',\n",
    "    'access',\n",
    "    'wiki',\n",
    "    'duplicated',\n",
    "    'facet of',\n",
    "    'translation',\n",
    "    'via',\n",
    "    'classification'\n",
    "]\n",
    "\n",
    "def _check_if_in_exclude_list(property_label):\n",
    "    if not property_label:\n",
    "        return True\n",
    "    for exclude_word in property_exclude_list:\n",
    "        if exclude_word in property_label.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def _construct_ground_truth(entity_property_map, property_id_label_map):\n",
    "    ground_truth = {}\n",
    "    for property_id, property_label in property_id_label_map.items():\n",
    "        if property_id in entity_property_map:\n",
    "             for qid in entity_property_map[property_id]:\n",
    "                if property_label not in ground_truth:\n",
    "                    ground_truth[property_label] = []\n",
    "                \n",
    "                label = get_wikidata_label_from_id(qid)\n",
    "                if not label:\n",
    "                    continue\n",
    "                if label not in ground_truth[property_label]:\n",
    "                    ground_truth[property_label].append(label)\n",
    "\n",
    "    return ground_truth\n",
    "\n",
    "def get_overlap(property_label_map_1, property_label_map_2):\n",
    "    # get overlap between two property_label_maps \n",
    "    # i.e. the number of key value pairs that are the same\n",
    "    overlap = []\n",
    "    for property, labels in property_label_map_2.items():\n",
    "        if property in property_label_map_1 and len(set(property_label_map_1[property]) & set(labels)) > 0:\n",
    "            overlap.append((property, property_label_map_2[property]))\n",
    "    return overlap\n",
    "\n",
    "def _get_coupled_properties_count(  \n",
    "    ent_property_label_map,\n",
    "    property_label_map,\n",
    "    target_true,\n",
    "    ent_id,\n",
    "    qid\n",
    "):\n",
    "    coupled_properties = 0\n",
    "    for property, labels in property_label_map.items():\n",
    "        # subject is object of this entity\n",
    "        if ent_id in labels:\n",
    "            coupled_properties += 1\n",
    "        # target true is object of this entity\n",
    "        if target_true in labels:\n",
    "            coupled_properties += 1\n",
    "        # mutual property\n",
    "        if ent_id in labels and property in ent_property_label_map and qid in ent_property_label_map[property]:\n",
    "            coupled_properties += 1\n",
    "    return coupled_properties\n",
    "\n",
    "\n",
    "def construct_entity_properties(\n",
    "    original_entity, \n",
    "    related_entity_dicts, \n",
    "    ent_property_label_map,\n",
    "    target_true,\n",
    "    target_new,\n",
    "    subject\n",
    "):\n",
    "    coupled_entities = []\n",
    "    \n",
    "\n",
    "    for related_entity_dict in related_entity_dicts:\n",
    "        property_id_label_map = {}\n",
    "        mutual_properties = set()\n",
    "        subject_as_object = set()\n",
    "        target_true_as_object = set()\n",
    "        original_property_of_subject_as_object = set()\n",
    "        additional_properties = set()\n",
    "        related_entity_label = related_entity_dict['entity'].get_label()\n",
    "\n",
    "        dependant_prompt = f\"\"\"Write an essay about {related_entity_label}\n",
    "    Include the following information:\"\"\"\n",
    "        for property, labels in related_entity_dict['property_label_map'].items():\n",
    "            # get interesting properties\n",
    "            if original_entity.entity_id in labels:\n",
    "                property_label = get_wikidata_property_from_id(property).get_label()\n",
    "                if _check_if_in_exclude_list(property_label):\n",
    "                    continue\n",
    "                subject_as_object.add(property_label)\n",
    "                property_id_label_map[property] = property_label\n",
    "            if target_true in labels:\n",
    "                property_label = get_wikidata_property_from_id(property).get_label()\n",
    "                if _check_if_in_exclude_list(property_label):\n",
    "                    continue\n",
    "                target_true_as_object.add(property_label)\n",
    "                property_id_label_map[property] = property_label\n",
    "            if original_entity.entity_id in labels and property in ent_property_label_map and related_entity_dict['entity'].entity_id in ent_property_label_map[property]:\n",
    "                property_label = get_wikidata_property_from_id(property).get_label()\n",
    "                if _check_if_in_exclude_list(property_label):\n",
    "                    continue\n",
    "                mutual_properties.add(property_label)\n",
    "                property_id_label_map[property] = property_label\n",
    "            else:\n",
    "                property_label = get_wikidata_property_from_id(property).get_label()\n",
    "                if _check_if_in_exclude_list(property_label):\n",
    "                    continue\n",
    "                additional_properties.add(property_label)\n",
    "                property_id_label_map[property] = property_label\n",
    "\n",
    "        \n",
    "        # if there are additional overlap properties add them\n",
    "        overlap_properties = set()\n",
    "        for property, _ in related_entity_dict['overlap']:\n",
    "            # get property label\n",
    "            # make properties labels a deduped list\n",
    "            property_label = get_wikidata_property_from_id(property).get_label()\n",
    "            if _check_if_in_exclude_list(property_label):\n",
    "                continue\n",
    "            overlap_properties.add(property_label)\n",
    "            property_id_label_map[property] = property_label\n",
    "\n",
    "        # remove other properties from additional properties\n",
    "        additional_properties = additional_properties - overlap_properties - subject_as_object - target_true_as_object - mutual_properties\n",
    "\n",
    "        properties_added = set()\n",
    "        for property_label in original_property_of_subject_as_object:\n",
    "            if property_label in properties_added:\n",
    "                continue\n",
    "            dependant_prompt += f\"\\n- {property_label}\"\n",
    "            properties_added.add(property_label)\n",
    "        for property_label in mutual_properties:\n",
    "            if property_label in properties_added:\n",
    "                continue\n",
    "            dependant_prompt += f\"\\n- {property_label}\"\n",
    "            properties_added.add(property_label)\n",
    "        for property_label in target_true_as_object:\n",
    "            if property_label in properties_added:\n",
    "                continue\n",
    "            dependant_prompt += f\"\\n- {property_label}\"\n",
    "            properties_added.add(property_label)\n",
    "        for property_label in subject_as_object:\n",
    "            if property_label in properties_added:\n",
    "                continue\n",
    "            dependant_prompt += f\"\\n- {property_label}\"\n",
    "            properties_added.add(property_label)\n",
    "        for property_label in overlap_properties:\n",
    "            if property_label in properties_added:\n",
    "                continue\n",
    "            dependant_prompt += f\"\\n- {property_label}\"\n",
    "            properties_added.add(property_label)\n",
    "        # Don't add additional properties for since they are irrelevant mostly\n",
    "        # for property_label in additional_properties:\n",
    "        #     if property_label in properties_added:\n",
    "        #         continue\n",
    "        #     dependant_prompt += f\"\\n- {property_label}\"\n",
    "        #     properties_added.add(property_label)\n",
    "\n",
    "        ground_truth = _construct_ground_truth(\n",
    "                related_entity_dict['property_label_map'],\n",
    "                property_id_label_map\n",
    "        )\n",
    "        # filter out properties that are not in additional properties\n",
    "        overlapping_ground_truth = {}\n",
    "        not_overlapping_ground_truth = {}\n",
    "        for property_label, values in ground_truth.items():\n",
    "            if property_label in additional_properties:\n",
    "                not_overlapping_ground_truth[property_label] = values\n",
    "            else:\n",
    "                overlapping_ground_truth[property_label] = values\n",
    "        coupled_entities.append({\n",
    "            'entity': related_entity_label,\n",
    "            'coupled_prompt': dependant_prompt,\n",
    "            'coupled_relationship_string': f\"\\nRelationship to:\\n- {subject}\\n- {target_true}\\n- {target_new}\",\n",
    "            'mutual_properties': list(mutual_properties),\n",
    "            'subject_as_object': list(subject_as_object),\n",
    "            'target_true_as_object': list(target_true_as_object),\n",
    "            'overlap_properties': list(overlap_properties),\n",
    "            'original_property_of_subject_as_object': list(original_property_of_subject_as_object),\n",
    "            'overlapping_ground_truth': overlapping_ground_truth,\n",
    "            'not_overlapping_ground_truth': not_overlapping_ground_truth,\n",
    "            'additional_properties': list(additional_properties),\n",
    "            'entity_id': related_entity_dict['entity'].entity_id,\n",
    "        })\n",
    "    \n",
    "    # create story prompt for original entity\n",
    "    dependant_prompt = f\"\"\"Write an essay about {original_entity.get_label()}\n",
    "Include the following information:\"\"\"\n",
    "    \n",
    "    subject_properties = set()\n",
    "    property_id_label_map = {}\n",
    "    for property, _ in ent_property_label_map.items():\n",
    "        # make properties a deduped list\n",
    "        # get property label\n",
    "        property_label = get_wikidata_property_from_id(property).get_label()\n",
    "        \n",
    "        if _check_if_in_exclude_list(property_label):\n",
    "            continue\n",
    "        subject_properties.add(property_label)\n",
    "        property_id_label_map[property] = property_label\n",
    "\n",
    "    for property_label in subject_properties:\n",
    "        dependant_prompt += f\"\\n- {property_label}\"\n",
    "    \n",
    "    subject_entity = {\n",
    "        'properties': list(subject_properties),\n",
    "        'coupled_prompt': dependant_prompt,\n",
    "        'coupled_relationship_string': f\"\\nRelationship to:\\n- {related_entity_label}\\n- {target_true}\\n- {target_new}\",\n",
    "        'ground_truth': _construct_ground_truth(\n",
    "            ent_property_label_map,\n",
    "            property_id_label_map\n",
    "        ),\n",
    "        'entity_id': original_entity.entity_id,\n",
    "    }\n",
    "    # sort coupled entities by number of properties\n",
    "    return {\n",
    "        'subject_entity': subject_entity,\n",
    "        'coupled_entities': coupled_entities\n",
    "    }\n",
    "\n",
    "def construct_dataset_item(\n",
    "        subject, \n",
    "        target_true,\n",
    "        target_new\n",
    "    ):\n",
    "    ent = get_wikidata_item_from_label(subject)\n",
    "    if ent is None:\n",
    "        # print(f'Could not find entity for {subject}')\n",
    "        return None\n",
    "    target_ent = get_wikidata_item_from_label(target_true)\n",
    "    if target_ent is None:\n",
    "        # print(f'Could not find entity for {target_true}')\n",
    "        return None\n",
    "    items = get_coupled_entities(ent.entity_id, target_ent.entity_id)\n",
    "    if len(items) == 0:\n",
    "        # print(f'Could not find coupled entities for {subject} and {target_true}')\n",
    "        return None\n",
    "    # filter out items with the same label\n",
    "    items = list({\n",
    "        item.get_label(): item\n",
    "        for item in items\n",
    "        if item and item.get_label() and item.get_label() != ent.get_label()\n",
    "    }.values())\n",
    "    # get all claims for this item\n",
    "    claims = ent.get_truthy_claim_groups()\n",
    "    # for all claims get entity values\n",
    "    ent_property_label_map = {}\n",
    "    for property, claim_group in claims.items():\n",
    "        for claim in claim_group:\n",
    "            if 'WikibaseEntityId' in str(type(claim.mainsnak.datavalue)):\n",
    "                # TODO: ignore properties at this level (ids) for speed\n",
    "                if property not in ent_property_label_map:\n",
    "                    ent_property_label_map[property] = []\n",
    "                ent_property_label_map[property].append(claim.mainsnak.datavalue.value['id'])\n",
    "                #print(get_wikidata_item_from_id(claim.mainsnak.datavalue.value['id']))\n",
    "\n",
    "    # construct a property_label_map for all entities in property_label_map.values()\n",
    "    property_label_maps = {}\n",
    "    for item in items:\n",
    "        qid = item.entity_id\n",
    "        property_label_maps[qid] = {}\n",
    "        claims = item.get_truthy_claim_groups()\n",
    "        for property, claim_group in claims.items():\n",
    "            for claim in claim_group:\n",
    "                if 'WikibaseEntityId' in str(type(claim.mainsnak.datavalue)):\n",
    "                    if property not in property_label_maps[qid]:\n",
    "                        property_label_maps[qid][property] = []\n",
    "                    # TODO: ignore properties at this level (ids) for speed\n",
    "                    property_label_maps[qid][property].append(claim.mainsnak.datavalue.value['id'])\n",
    "\n",
    "    \n",
    "    # rank property_label_maps by overlap with property_label_map\n",
    "    entity_with_overlap = {}\n",
    "    for qid, property_label_map in property_label_maps.items():\n",
    "        for labels in property_label_map.values():\n",
    "            if ent.entity_id in labels and qid not in entity_with_overlap:\n",
    "                if qid == ent.entity_id:\n",
    "                    continue\n",
    "                overlap = get_overlap(ent_property_label_map, property_label_map)\n",
    "                overlap_count = len(overlap)\n",
    "                coupled_properties_count = _get_coupled_properties_count(\n",
    "                    ent_property_label_map,\n",
    "                    property_label_map,\n",
    "                    target_true,\n",
    "                    ent.entity_id,\n",
    "                    qid\n",
    "                )\n",
    "                entity_with_overlap[qid] = {\n",
    "                    'overlap': overlap,\n",
    "                    'interesting_property_count': overlap_count + coupled_properties_count,\n",
    "                    'entity': get_wikidata_item_from_id(qid),\n",
    "                    'property_label_map': property_label_map\n",
    "                }\n",
    "\n",
    "    entity_with_overlap = list(entity_with_overlap.values())\n",
    "    entity_with_overlap.sort(key=lambda x: x['interesting_property_count'], reverse=True)\n",
    "    if len(entity_with_overlap) == 0:\n",
    "        return None\n",
    "\n",
    "    prompts = construct_entity_properties(\n",
    "        ent, entity_with_overlap,\n",
    "        ent_property_label_map,\n",
    "        target_true,\n",
    "        target_new,\n",
    "        subject\n",
    "    )\n",
    "    return  {\n",
    "        **prompts,\n",
    "        'coupled_properties_count': sum([\n",
    "            entity['interesting_property_count']\n",
    "            for entity in entity_with_overlap\n",
    "        ]),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:33<02:43,  1.92s/it]Traceback (most recent call last):\n",
      "  File \"/var/folders/hk/gjvj191n5k7gzt9tg0z8s3km0000gn/T/ipykernel_6230/1269549894.py\", line 14, in <module>\n",
      "    out = construct_dataset_item(\n",
      "  File \"/var/folders/hk/gjvj191n5k7gzt9tg0z8s3km0000gn/T/ipykernel_6230/3958850435.py\", line 251, in construct_dataset_item\n",
      "    target_ent = get_wikidata_item_from_label(target_true)\n",
      "  File \"/var/folders/hk/gjvj191n5k7gzt9tg0z8s3km0000gn/T/ipykernel_6230/2434736406.py\", line 102, in get_wikidata_item_from_label\n",
      "    return WikidataItem(entity_dict)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/longform_edit_model_evals/lib/python3.9/site-packages/qwikidata/entity.py\", line 256, in __init__\n",
      "    self._validate_item_dict(item_dict)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/longform_edit_model_evals/lib/python3.9/site-packages/qwikidata/entity.py\", line 265, in _validate_item_dict\n",
      "    raise ValueError(\n",
      "ValueError: item_dict['type'] must be 'item' but found 'property'\n",
      " 17%|█▋        | 17/100 [00:35<02:07,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_dict['type'] must be 'item' but found 'property'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:41<00:00,  2.81s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import logging\n",
    "items = []\n",
    "np.random.seed(2)\n",
    "sample_dataset = np.random.choice(dataset, 100)\n",
    "\n",
    "for item in tqdm(sample_dataset):\n",
    "    # twinned cities seems to hard\n",
    "    subject = item['subject']\n",
    "    try:\n",
    "        out = construct_dataset_item(\n",
    "            subject, \n",
    "            target_true=item['answers'][0],\n",
    "            target_new=item['alt']\n",
    "        )\n",
    "        if not out:\n",
    "            #print(f\"no dependant prompts for {subject}\")\n",
    "            continue\n",
    "        if out['coupled_entities'] == []:\n",
    "            #print(f\"no coupled entities for {subject}\")\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(e)\n",
    "        \n",
    "        continue\n",
    "    \n",
    "    new_item = ({\n",
    "        **item,\n",
    "        'dependancies':  out\n",
    "    })\n",
    "    items.append(new_item)\n",
    "    \n",
    "    # append new item to dataset file without overwriting\n",
    "    with open('../data/zsre_with_dependancies.json', 'w') as f:\n",
    "        json.dump(items, f, indent=4)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "longform_edit_model_evals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
