{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: apt-get\n"
     ]
    }
   ],
   "source": [
    "!apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 0 if torch.cuda.is_available() else -1\n",
    "PATH = '../results/survey_ratings_dataset.csv'\n",
    "INDEX_COL_NAME = 'sample_id'\n",
    "INPUT_COL_NAME = 'content'\n",
    "TARGET_COL_NAME = 'score'\n",
    "\n",
    "df = pd.read_csv(PATH, index_col=INDEX_COL_NAME)\n",
    "df['score'] = df['score'].astype(int)\n",
    "test = Dataset.from_pandas(df.loc[df['split'] == 'human'])\n",
    "train = Dataset.from_pandas(df.loc[df['split'] == 'generated'])\n",
    "new_dataset = DatasetDict({\n",
    "    'train': train,\n",
    "    'test': test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>content</th>\n",
       "      <th>intervention</th>\n",
       "      <th>model</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94404544b0b793406c670af7b8d81328</th>\n",
       "      <td>new_fact_related_passage</td>\n",
       "      <td>4</td>\n",
       "      <td>\\n## Sample ID: 94404544b0b793406c670af7b8d813...</td>\n",
       "      <td>gptj_ft_edit</td>\n",
       "      <td>gptj</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05c78e49db4d281a1ab9668051f1f96c</th>\n",
       "      <td>new_fact_related_passage</td>\n",
       "      <td>2</td>\n",
       "      <td>\\n## Sample ID: 05c78e49db4d281a1ab9668051f1f9...</td>\n",
       "      <td>gptj_ft_edit</td>\n",
       "      <td>gptj</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9d9d308363672ff168e75c762b294e7c</th>\n",
       "      <td>new_fact_related_passage</td>\n",
       "      <td>2</td>\n",
       "      <td>\\n## Sample ID: 9d9d308363672ff168e75c762b294e...</td>\n",
       "      <td>gptj_ft_edit</td>\n",
       "      <td>gptj</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939cec7221766f459a0097a7016ca592</th>\n",
       "      <td>new_fact_related_passage</td>\n",
       "      <td>4</td>\n",
       "      <td>\\n## Sample ID: 939cec7221766f459a0097a7016ca5...</td>\n",
       "      <td>gptj_ft_edit</td>\n",
       "      <td>gptj</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8cbdf451adc9c0f1becaa38515caacc</th>\n",
       "      <td>new_fact_related_passage</td>\n",
       "      <td>4</td>\n",
       "      <td>\\n## Sample ID: b8cbdf451adc9c0f1becaa38515caa...</td>\n",
       "      <td>gptj_ft_edit</td>\n",
       "      <td>gptj</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ac4fbed8cb3000529cd0b86c78926b3</th>\n",
       "      <td>new_fact_related_passage</td>\n",
       "      <td>4</td>\n",
       "      <td>\\n## Sample ID: 2ac4fbed8cb3000529cd0b86c78926...</td>\n",
       "      <td>llama2_chat_no_edit</td>\n",
       "      <td>llama2</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d60c008509f213dfbf7b5199988c1ccc</th>\n",
       "      <td>new_fact_related_passage</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n## Sample ID: d60c008509f213dfbf7b5199988c1c...</td>\n",
       "      <td>llama2_chat_no_edit</td>\n",
       "      <td>llama2</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98e17c2a42a6bead15f576139f121f01</th>\n",
       "      <td>new_fact_related_passage</td>\n",
       "      <td>7</td>\n",
       "      <td>\\n## Sample ID: 98e17c2a42a6bead15f576139f121f...</td>\n",
       "      <td>llama2_chat_no_edit</td>\n",
       "      <td>llama2</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cf1e5ca0a69ef5dd194c14529db868d3</th>\n",
       "      <td>new_fact_related_passage</td>\n",
       "      <td>7</td>\n",
       "      <td>\\n## Sample ID: cf1e5ca0a69ef5dd194c14529db868...</td>\n",
       "      <td>llama2_chat_no_edit</td>\n",
       "      <td>llama2</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c14b56ed776a223c6f734f74ee451ac7</th>\n",
       "      <td>new_fact_related_passage</td>\n",
       "      <td>2</td>\n",
       "      <td>\\n## Sample ID: c14b56ed776a223c6f734f74ee451a...</td>\n",
       "      <td>llama2_chat_no_edit</td>\n",
       "      <td>llama2</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>796 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     label  score  \\\n",
       "sample_id                                                           \n",
       "94404544b0b793406c670af7b8d81328  new_fact_related_passage      4   \n",
       "05c78e49db4d281a1ab9668051f1f96c  new_fact_related_passage      2   \n",
       "9d9d308363672ff168e75c762b294e7c  new_fact_related_passage      2   \n",
       "939cec7221766f459a0097a7016ca592  new_fact_related_passage      4   \n",
       "b8cbdf451adc9c0f1becaa38515caacc  new_fact_related_passage      4   \n",
       "...                                                    ...    ...   \n",
       "2ac4fbed8cb3000529cd0b86c78926b3  new_fact_related_passage      4   \n",
       "d60c008509f213dfbf7b5199988c1ccc  new_fact_related_passage      1   \n",
       "98e17c2a42a6bead15f576139f121f01  new_fact_related_passage      7   \n",
       "cf1e5ca0a69ef5dd194c14529db868d3  new_fact_related_passage      7   \n",
       "c14b56ed776a223c6f734f74ee451ac7  new_fact_related_passage      2   \n",
       "\n",
       "                                                                            content  \\\n",
       "sample_id                                                                             \n",
       "94404544b0b793406c670af7b8d81328  \\n## Sample ID: 94404544b0b793406c670af7b8d813...   \n",
       "05c78e49db4d281a1ab9668051f1f96c  \\n## Sample ID: 05c78e49db4d281a1ab9668051f1f9...   \n",
       "9d9d308363672ff168e75c762b294e7c  \\n## Sample ID: 9d9d308363672ff168e75c762b294e...   \n",
       "939cec7221766f459a0097a7016ca592  \\n## Sample ID: 939cec7221766f459a0097a7016ca5...   \n",
       "b8cbdf451adc9c0f1becaa38515caacc  \\n## Sample ID: b8cbdf451adc9c0f1becaa38515caa...   \n",
       "...                                                                             ...   \n",
       "2ac4fbed8cb3000529cd0b86c78926b3  \\n## Sample ID: 2ac4fbed8cb3000529cd0b86c78926...   \n",
       "d60c008509f213dfbf7b5199988c1ccc  \\n## Sample ID: d60c008509f213dfbf7b5199988c1c...   \n",
       "98e17c2a42a6bead15f576139f121f01  \\n## Sample ID: 98e17c2a42a6bead15f576139f121f...   \n",
       "cf1e5ca0a69ef5dd194c14529db868d3  \\n## Sample ID: cf1e5ca0a69ef5dd194c14529db868...   \n",
       "c14b56ed776a223c6f734f74ee451ac7  \\n## Sample ID: c14b56ed776a223c6f734f74ee451a...   \n",
       "\n",
       "                                         intervention   model      split  \n",
       "sample_id                                                                 \n",
       "94404544b0b793406c670af7b8d81328         gptj_ft_edit    gptj  generated  \n",
       "05c78e49db4d281a1ab9668051f1f96c         gptj_ft_edit    gptj  generated  \n",
       "9d9d308363672ff168e75c762b294e7c         gptj_ft_edit    gptj  generated  \n",
       "939cec7221766f459a0097a7016ca592         gptj_ft_edit    gptj  generated  \n",
       "b8cbdf451adc9c0f1becaa38515caacc         gptj_ft_edit    gptj  generated  \n",
       "...                                               ...     ...        ...  \n",
       "2ac4fbed8cb3000529cd0b86c78926b3  llama2_chat_no_edit  llama2  generated  \n",
       "d60c008509f213dfbf7b5199988c1ccc  llama2_chat_no_edit  llama2  generated  \n",
       "98e17c2a42a6bead15f576139f121f01  llama2_chat_no_edit  llama2  generated  \n",
       "cf1e5ca0a69ef5dd194c14529db868d3  llama2_chat_no_edit  llama2  generated  \n",
       "c14b56ed776a223c6f734f74ee451ac7  llama2_chat_no_edit  llama2  generated  \n",
       "\n",
       "[796 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\n",
    "    (df['split'] == 'generated') &\n",
    "    (df['label'] == 'new_fact_related_passage')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'score', 'content', 'intervention', 'model', 'split', 'sample_id'],\n",
       "        num_rows: 7164\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'score', 'content', 'intervention', 'model', 'split', 'sample_id'],\n",
       "        num_rows: 648\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.remove_columns(\n",
    "    ['label', 'score', 'content', 'intervention', 'model', 'split', 'sample_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/usr/local/Caskroom/miniconda/base/envs/longform_edit_model_evals/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mesure the token length of each sample\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "lengths = []\n",
    "for sample in new_dataset['train']:\n",
    "    lengths.append(len(\n",
    "        tokenizer.encode(sample['content'])\n",
    "    ))\n",
    "\n",
    "# plot the distribution of token lengths\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lengths, bins=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6291dc47384779bd2566bd0b2ac1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7164 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbd611a16bf49f7b9f6e56be5e3def3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"content\"], truncation=True, max_length=1024)\n",
    "\n",
    "tokenized_dataset = new_dataset.map(preprocess_function, batched=True) # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c241611517074f829b2f53bb1a0bf113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['pooler.dense.bias', 'classifier.weight', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/deberta-v3-large\", \n",
    "    num_labels=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    precision = load_metric(\"precision\")\n",
    "    recall = load_metric(\"recall\")\n",
    "    f1 = load_metric(\"f1\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        **f1.compute(predictions=predictions, references=labels, average='micro'),\n",
    "        **precision.compute(predictions=predictions, references=labels, average='micro'),\n",
    "        **recall.compute(predictions=predictions, references=labels, average='micro')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Looks like you do not have git-lfs installed, please install. You can install from https://git-lfs.github.com/. Then run `git lfs install` (you only have to do this once).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/longform_edit_model_evals/lib/python3.9/site-packages/huggingface_hub/repository.py:574\u001b[0m, in \u001b[0;36mRepository.check_git_versions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 574\u001b[0m     lfs_version \u001b[39m=\u001b[39m run_subprocess(\u001b[39m\"\u001b[39;49m\u001b[39mgit-lfs --version\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocal_dir)\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m    575\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/longform_edit_model_evals/lib/python3.9/site-packages/huggingface_hub/utils/_subprocess.py:83\u001b[0m, in \u001b[0;36mrun_subprocess\u001b[0;34m(command, folder, check, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m     folder \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(folder)\n\u001b[0;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m subprocess\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m     84\u001b[0m     command,\n\u001b[1;32m     85\u001b[0m     stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[1;32m     86\u001b[0m     stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[1;32m     87\u001b[0m     check\u001b[39m=\u001b[39;49mcheck,\n\u001b[1;32m     88\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     89\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mreplace\u001b[39;49m\u001b[39m\"\u001b[39;49m,  \u001b[39m# if not utf-8, replace char by �\u001b[39;49;00m\n\u001b[1;32m     90\u001b[0m     cwd\u001b[39m=\u001b[39;49mfolder \u001b[39mor\u001b[39;49;00m os\u001b[39m.\u001b[39;49mgetcwd(),\n\u001b[1;32m     91\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     92\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/longform_edit_model_evals/lib/python3.9/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m--> 505\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/longform_edit_model_evals/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    952\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    953\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    954\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    955\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    956\u001b[0m                         errread, errwrite,\n\u001b[1;32m    957\u001b[0m                         restore_signals,\n\u001b[1;32m    958\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    959\u001b[0m                         start_new_session)\n\u001b[1;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/longform_edit_model_evals/lib/python3.9/subprocess.py:1821\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1820\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1821\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1822\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'git-lfs'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdeberta-v3-survey-rater\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39m\u001b[39m6e-6\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# fp16=True # switch off if not using GPU\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     args\u001b[39m=\u001b[39;49mtraining_args,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     train_dataset\u001b[39m=\u001b[39;49mtokenized_dataset[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     eval_dataset\u001b[39m=\u001b[39;49mtokenized_dataset[\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     tokenizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     data_collator\u001b[39m=\u001b[39;49mdata_collator,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39;49mcompute_metrics,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/domenicrosati/src/longform_edit_model_evals/Notebooks/train_rater_models.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/longform_edit_model_evals/lib/python3.9/site-packages/transformers/trainer.py:563\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39m# Create clone of distant repo and output directory if needed\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpush_to_hub:\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_git_repo(at_init\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    564\u001b[0m     \u001b[39m# In case of pull, we need to make sure every process has the latest.\u001b[39;00m\n\u001b[1;32m    565\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/longform_edit_model_evals/lib/python3.9/site-packages/transformers/trainer.py:3571\u001b[0m, in \u001b[0;36mTrainer.init_git_repo\u001b[0;34m(self, at_init)\u001b[0m\n\u001b[1;32m   3569\u001b[0m create_repo(repo_name, token\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_token, private\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_private_repo, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   3570\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3571\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrepo \u001b[39m=\u001b[39m Repository(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49moutput_dir, clone_from\u001b[39m=\u001b[39;49mrepo_name, token\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mhub_token)\n\u001b[1;32m   3572\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m   3573\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39moverwrite_output_dir \u001b[39mand\u001b[39;00m at_init:\n\u001b[1;32m   3574\u001b[0m         \u001b[39m# Try again after wiping output_dir\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/longform_edit_model_evals/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/longform_edit_model_evals/lib/python3.9/site-packages/huggingface_hub/repository.py:504\u001b[0m, in \u001b[0;36mRepository.__init__\u001b[0;34m(self, local_dir, clone_from, repo_type, token, git_user, git_email, revision, skip_lfs_files, client)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip_lfs_files \u001b[39m=\u001b[39m skip_lfs_files\n\u001b[1;32m    502\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient \u001b[39m=\u001b[39m client \u001b[39mif\u001b[39;00m client \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m HfApi()\n\u001b[0;32m--> 504\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_git_versions()\n\u001b[1;32m    506\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(token, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    507\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhuggingface_token: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m token\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/longform_edit_model_evals/lib/python3.9/site-packages/huggingface_hub/repository.py:576\u001b[0m, in \u001b[0;36mRepository.check_git_versions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m     lfs_version \u001b[39m=\u001b[39m run_subprocess(\u001b[39m\"\u001b[39m\u001b[39mgit-lfs --version\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_dir)\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m    575\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLooks like you do not have git-lfs installed, please install.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m You can install from https://git-lfs.github.com/.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m Then run `git lfs install` (you only have to do this once).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m     )\n\u001b[1;32m    581\u001b[0m logger\u001b[39m.\u001b[39minfo(git_version \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m lfs_version)\n",
      "\u001b[0;31mOSError\u001b[0m: Looks like you do not have git-lfs installed, please install. You can install from https://git-lfs.github.com/. Then run `git lfs install` (you only have to do this once)."
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"deberta-v3-survey-rater\",\n",
    "    learning_rate=6e-6,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    push_to_hub=True,\n",
    "    hub_token=\"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\",\n",
    "    fp16=True # switch off if not using GPU\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"].sample(1),\n",
    "    eval_dataset=tokenized_dataset[\"test\"].sample(1),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
